# -*- coding: utf-8 -*-
"""
Created on Tue Mar 19 15:47:02 2019

@author: akash
"""

################################################################################
# ENVIRONMENT PREP

### Basic Packages

import os

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as st

from sklearn import metrics
from sklearn.model_selection import train_test_split as tts
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

import datetime as DT
from imblearn.over_sampling import SMOTE
from collections import Counter

from pandas.plotting import scatter_matrix
from datetime import datetime
from datetime import date
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
from statsmodels.discrete.discrete_model import Logit

### Provide the path here
os.chdir('C:\\Users\\akash\\Desktop\\GWU\\6501_Capstone\\data')
################################################################################

### Data Load
df1_flu16 = pd.read_excel('FluShots20162017v2.xlsx',sheet_name='2016')
df1_flu16.columns.values[7] = "Pt Ins"
df1_flu16 = df1_flu16.drop(['Diagnosis Codes','Diagnosis Codes_1'], axis =1)
df1_flu16.rename(columns={'Diagnosis Codes_2':'Diagnosis Codes','Account Number':'AcctNum'}, inplace=True)
df1_flu16['year'] = 2016
df1_flu17 = pd.read_excel('FluShots20162017v2.xlsx',sheet_name='2017')
df1_flu17.rename(columns={'Pt Address 1':'Pt Address 2','CPT Description':'Pt Address 1','CPT.1':'CPT Description','Account Number':'AcctNum'}, inplace=True)
df1_flu17['year'] = 2017
df1_flu1617 = pd.concat([df1_flu16,df1_flu17], sort = False)
df1_flu1617 = df1_flu1617[pd.to_numeric(df1_flu1617['AcctNum'], errors='coerce').notnull()]
df1_flu1617['AcctNum'] = pd.to_numeric(df1_flu1617['AcctNum'])

present_date = pd.Timestamp(DT.datetime.now())
relative_date = DT.datetime(2019,12,31)
df1_flu1617['Pt DOB'] = pd.to_datetime(df1_flu1617['Pt DOB'], format='%m%d%y')
df1_flu1617['Pt DOB'] = df1_flu1617['Pt DOB'].where(df1_flu1617['Pt DOB'] < relative_date, df1_flu1617['Pt DOB'] -  np.timedelta64(100, 'Y'))
df1_flu1617['Pt_Age'] = (relative_date - df1_flu1617['Pt DOB']).astype('<m8[Y]')

df1_fluDx = pd.read_excel('DiagnosisReport_20162017.xlsx',sheet_name='PT1005_pat_diagnosis_list.rpt')
df1_fluDx = df1_fluDx.copy(deep = True)
df1_fluDx.rename(columns={'Patient account':'AcctNum'}, inplace=True)
df1_fluDx = df1_fluDx[['AcctNum']]
df1_fluDx = df1_fluDx.dropna(how = 'all')
df1_fluDx['AcctNum'] = df1_fluDx['AcctNum'].str.split('-').str[0]
df1_fluDx = df1_fluDx[pd.to_numeric(df1_fluDx['AcctNum'], errors='coerce').notnull()]
df1_fluDx['AcctNum'] = pd.to_numeric(df1_fluDx['AcctNum'])
df1_fluDx['FluDx_YES'] = df1_fluDx.notnull().all(1).astype(int)
df1_fluDx =df1_fluDx.reset_index(drop = True)

df1 = pd.merge(df1_flu1617,df1_fluDx,left_on = 'AcctNum',right_on = 'AcctNum', how = 'left')
df1['FluDx_YES'].replace(np.nan,'0',inplace=True)
df1['FluDx_YES'] = pd.to_numeric(df1['FluDx_YES'])
df1.columns = df1.columns.str.upper()

#df1.to_excel("df1.xlsx")
df1 = pd.read_excel('df1.xlsx',sheet_name='Sheet1')

################################################################################

df1b = df1.copy(deep = False)
df1b = df1.drop(['ACCTNUM','PCP','LMG PRACTICE','DOS','DIAGNOSIS CODES',
        'PLACE OF SERVICE', 'CPT DESCRIPTION','PT ADDRESS 1',
        'PT ADDRESS 2','PT CITY', 'PT ZIP', 'PT DOB', 'UNITS', 'YEAR'], axis=1)
print(df1b.shape)


print(df1b.isnull().sum())                                                       #Null check again
### Dropping Rows
df1b.dropna(inplace=True)

### Value Counts
for f in df1b.columns:
    print(df1b[f].value_counts())

################################################################################

# Lower Limit Thresholds
lt_pt_state = 90
lt_pcp_speciality = 35
lt_pt_ins = 14
lt_pt_race = 30
lt_cpt = 15

### Combining Variables into Other

df1b['AGE_BIN']= pd.cut(df1b['PT_AGE'],[0,7,17,54,106], right = True, labels = ['Baby','Child','Adult','Senior'] )
# (0,7]|(7,17]|(17,54]|(54,106]

series = pd.value_counts(df1b['PT STATE'])
mask = (series/series.sum() * 100)                                              # To replace df['column'] use np.where I.e
mask = (series/series.sum() * 100).lt(lt_pt_state)                                        # lt(%); where % is the cut off
df1b['PT STATE'] = np.where(df1b['PT STATE'].isin(series[mask].index),'Other',df1b['PT STATE'])

series = pd.value_counts(df1b['PCP SPECIALTY'])
mask = (series/series.sum() * 100)
mask = (series/series.sum() * 100).lt(lt_pcp_speciality)
df1b['PCP SPECIALTY'] = np.where(df1b['PCP SPECIALTY'].isin(series[mask].index),'Other',df1b['PCP SPECIALTY'])

series = pd.value_counts(df1b['PT INS'])
mask = (series/series.sum() * 100)
mask = (series/series.sum() * 100).lt(lt_pt_ins)
df1b['PT INS'] = np.where(df1b['PT INS'].isin(series[mask].index),'Other',df1b['PT INS'])

df1b['PT RACE'].replace('_R','Other',inplace=True)                               # DOES NOT WORK WELL, DUPE OF 210 and 202
series = pd.value_counts(df1b['PT RACE'])
mask = (series/series.sum() * 100)
mask = (series/series.sum() * 100).lt(lt_pt_race)
df1b['PT RACE'] = np.where(df1b['PT RACE'].isin(series[mask].index),'Other',df1b['PT RACE'])

series = pd.value_counts(df1b['CPT'])
mask = (series/series.sum() * 100)
mask = (series/series.sum() * 100).lt(lt_cpt)
df1b['CPT'] = np.where(df1b['CPT'].isin(series[mask].index),'Other',df1b['CPT'])

new = series[~mask]
new['Other'] = series[mask].sum()
series.index = np.where(series.index.isin(series[mask].index),'Other',series.index)

#df1b.to_excel("df1b.xlsx")

################################################################################
df2 = df1b.copy(deep = True)

df2 = pd.get_dummies(df1b,columns = ['PT GENDER','PT STATE','PCP SPECIALTY','PT INS','CPT','AGE_BIN'], \
                     prefix = ['Gndr','State','Spclty','Ins','CPT','Age'])
print(df2.dtypes)


df2_qual = df2.select_dtypes(include=['object']).copy()
df2_quant = df2.select_dtypes(include=['int64','uint8']).copy()

df2_feats = list(df2)
print(df2.groupby('FLUDX_YES').mean() )

#df2.to_excel("df2.xlsx")
################################################################################

### df2 -- regular and smote

x = df2.drop(['FLUDX_YES','PT RACE','PT_AGE'],axis = 1 ).astype(float)
y = pd.DataFrame(df2['FLUDX_YES'].astype(float))

x_train, x_test, y_train, y_test = tts(x, y, test_size=0.3, random_state=5026)

print("Shape of x_train dataset: ", x_train.shape)
print("Shape of y_train dataset: ", y_train.shape)
print("Shape of x_test dataset: ", x_test.shape)
print("Shape of y_test dataset: ", y_test.shape)

sm = SMOTE(random_state=5026)
x_train_smote, y_train_smote = sm.fit_sample(x_train, y_train.values.ravel())
print('Resampled dataset shape %s' % Counter(y_train_smote))
traincols = list(x)
x_train_smote = pd.DataFrame(data=x_train_smote, columns = traincols).reset_index(drop = True)

y_train_smote = pd.DataFrame(data = y_train_smote).reset_index(drop = True)
y_train_smote.rename(columns={0:'FLUDX_YES'}, inplace=True)

df2smote_train = x_train_smote.join(y_train_smote)
df2_test = x_test.join(y_test)
df2smote = pd.concat([df2smote_train,df2_test])
df2smote.shape

df2smote.to_excel("df2smote.xlsx")

################################################################################
# DF3 # NOT USING PCA ANYMORE

# Feature Selection using Correlation Rank
 #https://blog.datadive.net/selecting-good-features-part-iii-random-forests/

print("Find most important features relative to DV")
df2_corr = df2.corr()
df2_corr.sort_values(["FLUDX_YES"], ascending = False, inplace = True)
print(df2_corr.FLUDX_YES)
df2_feats = list(df2)

corr_traincols=['Age_1','Spclty_Pediatrics','CPT_90686', 'CPT_90685','Ins_CIGNA','State_VA','Ins_MCAID','Ins_BCBS','Gndr_M', 'Ins_TRICARE']

df3 = df2_quant.copy(deep = True)
df3 = df3[corr_traincols].astype(float)

# Build the model
#pca = PCA(n_components=30)
# Reduce the data, output is ndarray
#df3 = pca.fit_transform(df3)


# Inspect shape of the `reduced_data`
df3.shape

# print out the reduced data
#print(df3)

df3 = pd.DataFrame(data=df3, columns = corr_traincols).reset_index(drop = True)
################################################################################

### SMOTE (df3)

#traincols =['Yr_2016','Yr_2017','Gndr_F','Gndr_M',
#            'State_MD','State_Other','State_VA','State_WV',
#            'Spclty_Family Practice','Spclty_Internal Medicine','Spclty_Other',
#            'Ins_AETNA','Ins_BCBS','Ins_CIGNA','Ins_MCAID','Ins_MCARE','Ins_Other','Ins_TRICARE','Ins_UNITED',
#            'CPT_90658', 'CPT_90662', 'CPT_90685','CPT_90686', 'CPT_90688', 'CPT_Other',
#            'Age_1','Age_2','Age_3','Age_4','Age_5']

y = pd.DataFrame(df2['FLUDX_YES'].astype(float))
x = df3[corr_traincols].astype(float)

x_train, x_test, y_train, y_test = tts(x, y, test_size=0.3, random_state=5026)

print("Number transactions x_train dataset: ", x_train.shape)
print("Number transactions y_train dataset: ", y_train.shape)
print("Number transactions x_test dataset: ", x_test.shape)
print("Number transactions y_test dataset: ", y_test.shape)


sm = SMOTE(random_state=5026)
x_train_smote, y_train_smote = sm.fit_sample(x_train, y_train.values.ravel())

print('After OverSampling, the shape of train_X: {}'.format(x_train_smote.shape))
print('After OverSampling, the shape of train_y: {} \n'.format(y_train_smote.shape))

print("After OverSampling, counts of label '1': {}".format(sum(y_train_smote==1)))
print("After OverSampling, counts of label '0': {}".format(sum(y_train_smote==0)))


x_train_smote = pd.DataFrame(data=x_train_smote, columns = corr_traincols).reset_index(drop = True)

y_train_smote = pd.DataFrame(data = y_train_smote).reset_index(drop = True)
y_train_smote.rename(columns={0:'FLUDX_YES'}, inplace=True)

################################################################################

# DF4 DECISION TREE + Mean decrease impurity

## Partition Data (DecisionTree)
dt_x = df2_quant.drop(['UNITS','PTAGE','Yr_2016','Yr_2017','FLUDX_YES'],axis=1,inplace=False)
df4_feats = list(dt_x)
dt_y = df2_quant[['FLUDX_YES']]
x_train, x_test, y_train, y_test =tts(dt_x, dt_y, test_size = 0.3, random_state=6202)
#print(x_train.dtypes)

## Depth Determination (DecisionTree)
### Range of values to try, and where to store MSE output
max_depth_range = range(1, 12)
all_MSE_scores = []

### Calculate MSE for each value of max_depth
for depth in max_depth_range:
    treereg = DecisionTreeRegressor(max_depth=depth, random_state=5026)
    MSE_scores = cross_val_score(treereg, x_train, y_train, cv=12, scoring='neg_mean_squared_error')
    all_MSE_scores.append(np.mean(np.sqrt(-MSE_scores)))

### Plot max_depth (x-axis) versus MSE (y-axis)
plt.figure(5)
plt.plot(max_depth_range, all_MSE_scores)
plt.title('Max Depth Range Plot (Decision Tree)')
plt.xlabel('max_depth')
plt.ylabel('MSE (lower is better)')
plt.show()

## Feature Importance
### Based on max_depth plot, depth = 8 is most ideal
treereg = DecisionTreeRegressor(max_depth=3, random_state=5026)
treereg.fit(x_train, y_train)

### "Gini importance" of each feature:
#print(pd.DataFrame({'feature':df4_feats, 'importance':sorted(treereg.feature_importances_ *1000, reverse = True)}))

### Mean decrease impurity
print( "Features sorted by their score:" )
print( sorted(zip(map(lambda x_train: round(x_train, 4), treereg.feature_importances_ *1000 ), df4_feats), reverse=True))

imprty_traincols=['Age_1','State_WV','Spclty_Pediatrics','CPT_90688','Ins_Other','State_VA']

df4 = df2_quant.copy(deep = True)
df4 = df4[imprty_traincols].astype(float)

################################################################################

### SMOTE (df4)

traincols =['Gndr_F','Gndr_M',
            'State_MD','State_Other','State_VA','State_WV',
            'Spclty_Family Practice','Spclty_Internal Medicine','Spclty_Other',
            'Ins_AETNA','Ins_BCBS','Ins_CIGNA','Ins_MCAID','Ins_MCARE','Ins_Other','Ins_TRICARE','Ins_UNITED',
            'Age_1','Age_2','Age_3','Age_4','Age_5']

y = pd.DataFrame(df2['FLUDX_YES'].astype(float))
x = df2[imprty_traincols].astype(float)

x_train, x_test, y_train, y_test = tts(x, y, test_size=0.3, random_state=5026)

print("Number transactions x_train dataset: ", x_train.shape)
print("Number transactions y_train dataset: ", y_train.shape)
print("Number transactions x_test dataset: ", x_test.shape)
print("Number transactions y_test dataset: ", y_test.shape)


sm = SMOTE(random_state=5026)
x_train_smote, y_train_smote = sm.fit_sample(x_train, y_train.values.ravel())

print('After OverSampling, the shape of train_X: {}'.format(x_train_smote.shape))
print('After OverSampling, the shape of train_y: {} \n'.format(y_train_smote.shape))

print("After OverSampling, counts of label '1': {}".format(sum(y_train_smote==1)))
print("After OverSampling, counts of label '0': {}".format(sum(y_train_smote==0)))


x_train_smote = pd.DataFrame(data=x_train_smote, columns = imprty_traincols).reset_index(drop = True)

y_train_smote = pd.DataFrame(data = y_train_smote).reset_index(drop = True)
y_train_smote.rename(columns={0:'FLUDX_YES'}, inplace=True)
################################################################################
# DF5

# Feature Selection using Correlation Rank
 #https://blog.datadive.net/selecting-good-features-part-iii-random-forests/


traincols=['Age_1','Spclty_Pediatrics','CPT_90686', 'CPT_90685','Ins_CIGNA','State_VA','Ins_MCAID','Ins_BCBS','Gndr_M', 'Ins_TRICARE']

df5 = df2_quant.copy(deep = True)
df5 = df3[corr_traincols].astype(float)



# Inspect shape of the `reduced_data`
df5.shape

# print out the reduced data
#print(df3)

df5 = pd.DataFrame(data=df3, columns = corr_traincols).reset_index(drop = True)
################################################################################

### SMOTE (df5)

#traincols =['Yr_2016','Yr_2017','Gndr_F','Gndr_M',
#            'State_MD','State_Other','State_VA','State_WV',
#            'Spclty_Family Practice','Spclty_Internal Medicine','Spclty_Other',
#            'Ins_AETNA','Ins_BCBS','Ins_CIGNA','Ins_MCAID','Ins_MCARE','Ins_Other','Ins_TRICARE','Ins_UNITED',
#            'CPT_90658', 'CPT_90662', 'CPT_90685','CPT_90686', 'CPT_90688', 'CPT_Other',
#            'Age_1','Age_2','Age_3','Age_4','Age_5']

y = pd.DataFrame(df2['FLUDX_YES'].astype(float))
x = df3[corr_traincols].astype(float)

x_train, x_test, y_train, y_test = tts(x, y, test_size=0.3, random_state=5026)

print("Number transactions x_train dataset: ", x_train.shape)
print("Number transactions y_train dataset: ", y_train.shape)
print("Number transactions x_test dataset: ", x_test.shape)
print("Number transactions y_test dataset: ", y_test.shape)


sm = SMOTE(random_state=5026)
x_train_smote, y_train_smote = sm.fit_sample(x_train, y_train.values.ravel())

print('After OverSampling, the shape of train_X: {}'.format(x_train_smote.shape))
print('After OverSampling, the shape of train_y: {} \n'.format(y_train_smote.shape))

print("After OverSampling, counts of label '1': {}".format(sum(y_train_smote==1)))
print("After OverSampling, counts of label '0': {}".format(sum(y_train_smote==0)))


x_train_smote = pd.DataFrame(data=x_train_smote, columns = corr_traincols).reset_index(drop = True)

y_train_smote = pd.DataFrame(data = y_train_smote).reset_index(drop = True)
y_train_smote.rename(columns={0:'FLUDX_YES'}, inplace=True)

################################################################################

### DV Density
plt.figure(2); plt.title('Normal')
sns.distplot(df2['FLUDX_YES'], kde=False, fit=st.norm)

################################################################################
#### Logistic Regression (sklearn) DF2
#df3 = df2_quant.copy(deep = False)
# prepare X and y
#x = df3.drop(['FLUDX_YES','UNITS','PTAGE'],axis=1,inplace=False) # PATIENT AGE!!!!!!!!!!!!!!!!!
#y = df3[['FLUDX_YES']]

#x_train, x_test, y_train, y_test =tts(x, y, test_size = 0.3, random_state=5026)

logit = LogisticRegression()
result = logit.fit(x_train,y_train)
#print(result.summary())

logit_yhat = logit.predict(x_test)
logit_prob = logit.predict_proba(x_test)
logit_ci90 = (np.percentile(logit_prob[:,1],90))
logit_threshold = logit_ci90
logit_yhat = np.where(logit_prob[:,1] >= logit_threshold,1,0)


logit_score =  round(metrics.accuracy_score(y_test, logit_yhat)*100,2)
print('\n Score logit:', metrics.accuracy_score(y_test, logit_yhat) ) #0.8584547181760608
#print(' \n Intercept logit: ',logit.intercept_)
logit_coef = pd.DataFrame(logit.coef_[0], x_test.columns, columns=['logit_Coefficients'])
logit_confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, logit_yhat), columns=['predicted 0','predicted 1'], index =['actual 0','actual 1'] )
print('\n Confusion Matrix logit SMOTE: \n',logit_confusion_matrix)
logit_auc = metrics.roc_auc_score(y_test, logit_yhat)
print('\n AUC: \n', logit_auc)  #0.568841245785207

### Evaluation Metrics
tn = logit_confusion_matrix.iloc[0,0]
fp = logit_confusion_matrix.iloc[0,1]
fn = logit_confusion_matrix.iloc[1,0]
tp = logit_confusion_matrix.iloc[1,1]
sensitivity = tp/(tp+fn)*100                                                    #print(sensitivity) # this percent... of all True values, the model was able to predict
specificity = tn / (tn + fp) *100                                               #print(specificity) # this percent... of all False values, the model was able to predict
################################################################################
#### Logistic Regression (sklearn) DF3
#df3 = df2_quant.copy(deep = False)
# prepare X and y
#x = df3.drop(['FLUDX_YES','UNITS','PTAGE'],axis=1,inplace=False) # PATIENT AGE!!!!!!!!!!!!!!!!!
#y = df3[['FLUDX_YES']]

#x_train, x_test, y_train, y_test =tts(x, y, test_size = 0.3, random_state=5026)

logit = LogisticRegression()
result = logit.fit(x_train,y_train)
#print(result.summary())

logit_yhat = logit.predict(x_test)
logit_prob = logit.predict_proba(x_test)
logit_ci90 = (np.percentile(logit_prob[:,1],90))
logit_threshold = logit_ci90
logit_yhat = np.where(logit_prob[:,1] >= logit_threshold,1,0)


logit_score =  round(metrics.accuracy_score(y_test, logit_yhat)*100,2)
print('\n Score logit:', metrics.accuracy_score(y_test, logit_yhat) ) #0.880050664977834
#print(' \n Intercept logit: ',logit.intercept_)
logit_coef = pd.DataFrame(logit.coef_[0], x_test.columns, columns=['logit_Coefficients'])
logit_confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, logit_yhat), columns=['predicted 0','predicted 1'], index =['actual 0','actual 1'] )
print('\n Confusion Matrix logit SMOTE: \n',logit_confusion_matrix)
logit_auc = metrics.roc_auc_score(y_test, logit_yhat)
print('\n AUC: \n', logit_auc)  #  0.558901607998342

### Evaluation Metrics
tn = logit_confusion_matrix.iloc[0,0]
fp = logit_confusion_matrix.iloc[0,1]
fn = logit_confusion_matrix.iloc[1,0]
tp = logit_confusion_matrix.iloc[1,1]
sensitivity = tp/(tp+fn)*100                                                    #print(sensitivity) # this percent... of all True values, the model was able to predict
specificity = tn / (tn + fp) *100                                               #print(specificity) # this percent... of all False values, the model was able to predict
################################################################################

#### Logistic Regression (sklearn) DF4
#df3 = df2_quant.copy(deep = False)
# prepare X and y
#x = df3.drop(['FLUDX_YES','UNITS','PTAGE'],axis=1,inplace=False) # PATIENT AGE!!!!!!!!!!!!!!!!!
#y = df3[['FLUDX_YES']]

#x_train, x_test, y_train, y_test =tts(x, y, test_size = 0.3, random_state=5026)

logit = LogisticRegression()
result = logit.fit(x_train,y_train)
#print(result.summary())

logit_yhat = logit.predict(x_test)
logit_prob = logit.predict_proba(x_test)
logit_ci90 = (np.percentile(logit_prob[:,1],90))
logit_threshold = logit_ci90
logit_yhat = np.where(logit_prob[:,1] >= logit_threshold,1,0)


logit_score =  round(metrics.accuracy_score(y_test, logit_yhat)*100,2)
print('\n Score logit:', metrics.accuracy_score(y_test, logit_yhat) ) #0.8235592146928435
#print(' \n Intercept logit: ',logit.intercept_)
logit_coef = pd.DataFrame(logit.coef_[0], x_test.columns, columns=['logit_Coefficients'])
logit_confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, logit_yhat), columns=['predicted 0','predicted 1'], index =['actual 0','actual 1'] )
print('\n Confusion Matrix logit SMOTE: \n',logit_confusion_matrix)
logit_auc = metrics.roc_auc_score(y_test, logit_yhat)
print('\n AUC: \n', logit_auc)  #  0.584751342

### Evaluation Metrics
tn = logit_confusion_matrix.iloc[0,0]
fp = logit_confusion_matrix.iloc[0,1]
fn = logit_confusion_matrix.iloc[1,0]
tp = logit_confusion_matrix.iloc[1,1]
sensitivity = tp/(tp+fn)*100                                                    #print(sensitivity) # this percent... of all True values, the model was able to predict
specificity = tn / (tn + fp) *100                                               #print(specificity) # this percent... of all False values, the model was able to predict
################################################################################
#### Logistic Regression (sklearn) SMOTE df2
#df3 = df2_quant.copy(deep = False)

# prepare X and y
#x = df3.drop(['FLUDX_YES','UNITS'],axis=1,inplace=False)
#y = df3[['FLUDX_YES']]

#x_train, x_test, y_train, y_test =tts(x, y, test_size = 0.3, random_state=5026)


logit = LogisticRegression()
result = logit.fit(x_train_smote,y_train_smote)

logit_yhat = logit.predict(x_test)
logit_prob = logit.predict_proba(x_test)
logit_ci90 = (np.percentile(logit_prob[:,1],90))
logit_threshold = logit_ci90
logit_yhat = np.where(logit_prob[:,1] >= logit_threshold,1,0)


logit_score =  round(metrics.accuracy_score(y_test, logit_yhat)*100,2)
print('\n Score logit:', metrics.accuracy_score(y_test, logit_yhat) ) #0.8560481317289423
#print(' \n Intercept logit: ',logit.intercept_)
logit_coef = pd.DataFrame(logit.coef_[0], x_test.columns, columns=['logit_Coefficients'])
logit_confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, logit_yhat), columns=['predicted 0','predicted 1'], index =['actual 0','actual 1'] )
print('\n Confusion Matrix logit: \n',logit_confusion_matrix)
logit_auc = metrics.roc_auc_score(y_test, logit_yhat)
print('\n AUC: \n', logit_auc) #0.5575

### Evaluation Metrics
tn = logit_confusion_matrix.iloc[0,0]
fp = logit_confusion_matrix.iloc[0,1]
fn = logit_confusion_matrix.iloc[1,0]
tp = logit_confusion_matrix.iloc[1,1]
sensitivity = tp/(tp+fn)*100                                                    #print(sensitivity) # this percent... of all True values, the model was able to predict
specificity = tn / (tn + fp) *100                                               #print(specificity) # this percent... of all False values, the model was able to predict
################################################################################

#### Logistic Regression (sklearn) SMOTE df3
#df3 = df2_quant.copy(deep = False)

# prepare X and y
#x = df3.drop(['FLUDX_YES','UNITS'],axis=1,inplace=False)
#y = df3[['FLUDX_YES']]

#x_train, x_test, y_train, y_test =tts(x, y, test_size = 0.3, random_state=5026)


logit = LogisticRegression()
result = logit.fit(x_train_smote,y_train_smote)

logit_yhat = logit.predict(x_test)
logit_prob = logit.predict_proba(x_test)
logit_ci90 = (np.percentile(logit_prob[:,1],90))
logit_threshold = logit_ci90
logit_yhat = np.where(logit_prob[:,1] >= logit_threshold,1,0)


logit_score =  round(metrics.accuracy_score(y_test, logit_yhat)*100,2)
print('\n Score logit:', metrics.accuracy_score(y_test, logit_yhat) ) #0.8797973400886637
#print(' \n Intercept logit: ',logit.intercept_)
logit_coef = pd.DataFrame(logit.coef_[0], x_test.columns, columns=['logit_Coefficients'])
logit_confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, logit_yhat), columns=['predicted 0','predicted 1'], index =['actual 0','actual 1'] )
print('\n Confusion Matrix logit: \n',logit_confusion_matrix)
logit_auc = metrics.roc_auc_score(y_test, logit_yhat)
print('\n AUC: \n', logit_auc) #0.550510259

### Evaluation Metrics
tn = logit_confusion_matrix.iloc[0,0]
fp = logit_confusion_matrix.iloc[0,1]
fn = logit_confusion_matrix.iloc[1,0]
tp = logit_confusion_matrix.iloc[1,1]
sensitivity = tp/(tp+fn)*100                                                    #print(sensitivity) # this percent... of all True values, the model was able to predict
specificity = tn / (tn + fp) *100                                               #print(specificity) # this percent... of all False values, the model was able to predict
################################################################################

#### Logistic Regression (sklearn) SMOTE df4
#df3 = df2_quant.copy(deep = False)

# prepare X and y
#x = df3.drop(['FLUDX_YES','UNITS'],axis=1,inplace=False)
#y = df3[['FLUDX_YES']]

#x_train, x_test, y_train, y_test =tts(x, y, test_size = 0.3, random_state=5026)


logit = LogisticRegression()
result = logit.fit(x_train_smote,y_train_smote)

logit_yhat = logit.predict(x_test)
logit_prob = logit.predict_proba(x_test)
logit_ci90 = (np.percentile(logit_prob[:,1],90))
logit_threshold = logit_ci90
logit_yhat = np.where(logit_prob[:,1] >= logit_threshold,1,0)


logit_score =  round(metrics.accuracy_score(y_test, logit_yhat)*100,2)
print('\n Score logit:', metrics.accuracy_score(y_test, logit_yhat) ) #0.8310956301456618
#print(' \n Intercept logit: ',logit.intercept_)
logit_coef = pd.DataFrame(logit.coef_[0], x_test.columns, columns=['logit_Coefficients'])
logit_confusion_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, logit_yhat), columns=['predicted 0','predicted 1'], index =['actual 0','actual 1'] )
print('\n Confusion Matrix logit: \n',logit_confusion_matrix)
logit_auc = metrics.roc_auc_score(y_test, logit_yhat)
print('\n AUC: \n', logit_auc) #0.5785534541374721

### Evaluation Metrics
tn = logit_confusion_matrix.iloc[0,0]
fp = logit_confusion_matrix.iloc[0,1]
fn = logit_confusion_matrix.iloc[1,0]
tp = logit_confusion_matrix.iloc[1,1]
sensitivity = tp/(tp+fn)*100                                                    #print(sensitivity) # this percent... of all True values, the model was able to predict
specificity = tn / (tn + fp) *100                                               #print(specificity) # this percent... of all False values, the model was able to predict
################################################################################

#df2
# SVC -->  https://elitedatascience.com/imbalanced-classes
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
svc = SVC(kernel='linear',
            class_weight='balanced', # penalize
            probability=True)

svc.fit(x_train, y_train)

# Predict on training set
svc_yhat = svc.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( svc_yhat ) )

# How's our accuracy?
print( metrics.accuracy_score(y_test, svc_yhat) ) # 0.5836605446485117

# What about AUROC?
svc_prob = svc.predict_proba(x_test)
svc_prob = [p[1] for p in svc_prob]
print( roc_auc_score(y_test, svc_prob) ) # 0.6473181635658544

################################################################################
#df3
# SVC -->  https://elitedatascience.com/imbalanced-classes
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
svc = SVC(kernel='linear',
            class_weight='balanced', # penalize
            probability=True)

svc.fit(x_train, y_train)

# Predict on training set
svc_yhat = svc.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( svc_yhat ) )

# How's our accuracy?
print( metrics.accuracy_score(y_test, svc_yhat) ) #0.5300823305889804

# What about AUROC?
svc_prob = svc.predict_proba(x_test)
svc_prob = [p[1] for p in svc_prob]
print( roc_auc_score(y_test, svc_prob) ) #0.6780682796470335

##############################################################################
#df4
# SVC -->  https://elitedatascience.com/imbalanced-classes
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
svc = SVC(kernel='linear',
            class_weight='balanced', # penalize
            probability=True)

svc.fit(x_train, y_train)

# Predict on training set
svc_yhat = svc.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( svc_yhat ) )

# How's our accuracy?
print( metrics.accuracy_score(y_test, svc_yhat) ) #0.5300823305889804

# What about AUROC?
svc_prob = svc.predict_proba(x_test)
svc_prob = [p[1] for p in svc_prob]
print( roc_auc_score(y_test, svc_prob) ) #0.6764161779300285

##############################################################################
# SVC -->  SMOTE DF2
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
svc = SVC(kernel='linear',
            class_weight='balanced', # penalize
            probability=True)

svc.fit(x_train_smote, y_train_smote)

# Predict on training set
svc_yhat = svc.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( svc_yhat ) )

# How's our accuracy?
print( metrics.accuracy_score(y_test, svc_yhat) ) # 0.6051931602279924

# What about AUROC?
svc_prob = svc.predict_proba(x_test)
svc_prob = [p[1] for p in svc_prob]
print( roc_auc_score(y_test, svc_prob) ) # 0.6462403024886211

################################################################################

# SVC -->  SMOTE DF3
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
svc = SVC(kernel='linear',
            class_weight='balanced', # penalize
            probability=True)

svc.fit(x_train_smote, y_train_smote)

# Predict on training set
svc_yhat = svc.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( svc_yhat ) )

# How's our accuracy?
print( metrics.accuracy_score(y_test, svc_yhat) ) #

# What about AUROC?
svc_prob = svc.predict_proba(x_test)
svc_prob = [p[1] for p in svc_prob]
print( roc_auc_score(y_test, svc_prob) ) #
##############################################################################

# SVC -->  SMOTE DF4
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
svc = SVC(kernel='linear',
            class_weight='balanced', # penalize
            probability=True)

svc.fit(x_train_smote, y_train_smote)

# Predict on training set
svc_yhat = svc.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( svc_yhat ) )

# How's our accuracy?
print( metrics.accuracy_score(y_test, svc_yhat) ) #0.5394553514882837

# What about AUROC?
svc_prob = svc.predict_proba(x_test)
svc_prob = [p[1] for p in svc_prob]
print( roc_auc_score(y_test, svc_prob) ) #0.661868789906019
##############################################################################

# Tree Model --> df2
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

class_wgts = {i: 1 for i in y_train}
class_wgts[1] = 10
class_wgts[0] = 1
class_wgts.pop('FLUDX_YES')

# Train model
tree = RandomForestClassifier( class_weight = class_wgts, random_state=5026)
tree.fit(x_train, y_train)

# Predict on training set
tree_yhat = tree.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( tree_yhat ) )


# How's our accuracy?
print( metrics.accuracy_score(y_test, tree_yhat) ) # 0.966624445851805


# What about AUROC?
tree_prob = tree.predict_proba(x_test)
tree_prob = [p[1] for p in tree_prob]
print( roc_auc_score(y_test, tree_prob) ) # 0.6793665953240706


################################################################################
# Tree Model --> SMOTE df2
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
tree = RandomForestClassifier()
tree.fit(x_train_smote, y_train_smote)

# Predict on training set
tree_yhat = tree.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( tree_yhat ) )


# How's our accuracy?
print( metrics.accuracy_score(y_test, tree_yhat) ) # 0.5980367321089297


# What about AUROC?
tree_prob = tree.predict_proba(x_test)
tree_prob = [p[1] for p in tree_prob]
print( roc_auc_score(y_test, tree_prob) ) # 0.673525358008306


################################################################################

# Tree Model --> df3
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
tree = RandomForestClassifier()
tree.fit(x_train, y_train)

# Predict on training set
tree_yhat = tree.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( tree_yhat ) )


# How's our accuracy?
print( metrics.accuracy_score(y_test, tree_yhat) ) #0.966624446

# What about AUROC?
tree_prob = tree.predict_proba(x_test)
tree_prob = [p[1] for p in tree_prob]
print( roc_auc_score(y_test, tree_prob) ) # 0.683327554

################################################################################

# Tree Model --> SMOTE df3
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
tree = RandomForestClassifier()
tree.fit(x_train_smote, y_train_smote)

# Predict on training set
tree_yhat = tree.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( tree_yhat ) )


# How's our accuracy?
print( metrics.accuracy_score(y_test, tree_yhat) ) # 0.6377454084863838


# What about AUROC?
tree_prob = tree.predict_proba(x_test)
tree_prob = [p[1] for p in tree_prob]
print( roc_auc_score(y_test, tree_prob) ) # 0.6811904523479286


################################################################################

################################################################################

# Tree Model --> df4
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
tree = RandomForestClassifier()
tree.fit(x_train, y_train)

# Predict on training set
tree_yhat = tree.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( tree_yhat ) )


# How's our accuracy?
print( metrics.accuracy_score(y_test, tree_yhat) ) #0.9664344521849272

# What about AUROC?
tree_prob = tree.predict_proba(x_test)
tree_prob = [p[1] for p in tree_prob]
print( roc_auc_score(y_test, tree_prob) ) # 0.6912616155909479

################################################################################

# Tree Model --> SMOTE df4
# Separate input features (X) and target variable (y)
#y = df.balance
#X = df.drop('balance', axis=1)

# Train model
tree = RandomForestClassifier()
tree.fit(x_train_smote, y_train_smote)

# Predict on training set
tree_yhat = tree.predict(x_test)

# Is our model still predicting just one class?
print( np.unique( tree_yhat ) )


# How's our accuracy?
print( metrics.accuracy_score(y_test, tree_yhat) ) # 0.5394553514882837


# What about AUROC?
tree_prob = tree.predict_proba(x_test)
tree_prob = [p[1] for p in tree_prob]
print( roc_auc_score(y_test, tree_prob) ) # 0.661868789906019


################################################################################


















